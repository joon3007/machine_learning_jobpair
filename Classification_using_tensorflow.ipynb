{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Job Pair (Classification)\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirement\n",
    "* python 2.x.x                                                         \n",
    "\n",
    "* Tensorflow 2.0  \n",
    "\n",
    "* CUDA 10.2  \n",
    "\n",
    "* Cudnn >= 7.6.2  \n",
    "\n",
    "* Pillow, SciPy, six, numpy, OpenCV 3.x.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment  \n",
    "\n",
    "* Ubuntu 18.04\n",
    "* Nvidia-docker 2.0.3\n",
    "* GeForce GTX1070 8G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation  \n",
    "* Traing 할수있는 데이터의 수를 늘리고자 회전, 가우시안 노이즈를 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os\n",
    "import cv2\n",
    "import preprocess.augmentation as aug #가우시안 노이즈를 사용하기위한 외부소스\n",
    "\n",
    "data_file_path = \"/data/faces_images\" # 데이터의 위치와 훈련데이터 정보가 있는 csv파일 경로\n",
    "label_file_path = \"/data/train_vision.csv\" \n",
    "\n",
    "f = open('/data/noise_train_vision.csv','w')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['filename','label'])\n",
    "\n",
    "with open(label_file_path) as path_list:\n",
    "    for data in enumerate(path_list):\n",
    "        if data[0] is 0: continue\n",
    "        filename, label = data[1].split(\",\")\n",
    "        filepath = os.path.join(data_file_path,filename)\n",
    "        \n",
    "        ### 가우시안 노이즈 이미지 생성\n",
    "        img = cv2.imread(filepath)\n",
    "        noised_img = aug.gaussian_noise(img, mean=0, var =10) \n",
    "        \n",
    "        ### Label파일 생성\n",
    "        wr.writerow([filename, int(label)])\n",
    "        cv2.imwrite(os.path.join(data_file_path,'noised_'+filename), noised_img)\n",
    "        wr.writerow(['noised_'+filename, int(label)])\n",
    "        \n",
    "        '''\n",
    "        for i in range(1,4):\n",
    "            img = img.rotate(90)\n",
    "            img.save(os.path.join(data_file_path,'rot'+str(90*i)+'_'+filename))\n",
    "            wr.writerow(['rot'+str(90*i)+'_'+filename, int(label)])\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "* 주어진 데이터 csv를 참고하여 데이터를 읽은 후 전처리하는 단계입니다.\n",
    "* keras의 데이터생성 함수의 경우 폴더 내부의 이미지를 읽어들여 Data Generator를 생성하기 때문에 이미지의 파일경로와 라벨을 가지고 데이터를 생성하는 flow_from_mapfile 구현.  \n",
    "* Feature 잘 분류하기 위해 데이터 처리 과정에서 horizontal flip, zoom, shear, rescale 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5850 images for training.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import preprocess.image as image\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "import random\n",
    "\n",
    "\n",
    "data_file_path = \"/data/faces_images\"\n",
    "label_file_path = \"/data/train_vision.csv\"\n",
    "initial_learning_rate = 0.001 \n",
    "image_size = 224\n",
    "class_num = 6\n",
    "batch_size = 16\n",
    "epoch = 60\n",
    "\n",
    "### GPU Memory 사용량을 제어하기 위한 코드 \n",
    "### 기존의 tensorflow 1.x 버전의 Session을 이용하여 할당하는데 필요한 memory만을 사용.\n",
    "'''\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.compat.v1.Session(config=config))\n",
    "'''\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "# 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "\n",
    "### 데이터 생성을 위한 path와 label리스트 생성\n",
    "filenames = []\n",
    "labels = []\n",
    "with open(label_file_path) as path_list:\n",
    "    for data in enumerate(path_list):\n",
    "        if data[0] is 0:\n",
    "            continue\n",
    "            \n",
    "        filename, label = data[1].split(\",\")\n",
    "        filenames.append(os.path.join(data_file_path,filename))\n",
    "        labels.append(int(label)-1)\n",
    "        \n",
    "    '''\n",
    "    random.seed(1)    \n",
    "    random.shuffle(filenames)\n",
    "    random.shuffle(labels)\n",
    "    '''\n",
    "    \n",
    "    print('Found %d images for training.' % (len(filenames)))\n",
    "    \n",
    "class_num = list(range(class_num))\n",
    "\n",
    "'''\n",
    "Class ImageDataGenerator\n",
    "- Training에 사용되는 데이터를 생성하고 queue에 전달해주는 iterator.\n",
    "  전달시 설정한 범위에서 random으로 filp, zoom, shearing을 수행하여 데이터를 보낸다.\n",
    "'''\n",
    "train_datagen = image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True)\n",
    "\n",
    "'''\n",
    "Class DataPathIterator (기존의 DirectoryInterator를 수정)\n",
    "- flow_from_mapfile의 return값. filename리스트를 읽어 데이터로 변환하며 random index를 통해 Training시 data batch\n",
    "  를 random하게 구성하여 전달한다.\n",
    "\n",
    "argment : \n",
    "        get_batches_of_transformed_samples : random index생성 및 이미지 로드를 하며 각 데이터 라벨에 대해 \n",
    "        one-hot encording을 수행한다.\n",
    "        \n",
    "        next : 데이터의 다음 batch를 반환.\n",
    "'''\n",
    "train_generator = train_datagen.flow_from_mapfile(class_num,filenames,labels,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Training\n",
    "* 전처리한 데이터를 사용하여 신경망을 훈련하는 단계로 훈련에 사용되는 Optimizer 종류, learning rate, epoch수 등을 조정하여 최적의 모델을 만드는 단계입니다.\n",
    "* tensorflow에서 지원하는 다양한 신경망을 편리하게 사용하기위해 net_factory 구현.\n",
    "* queue를 사용하여 데이터 흐름을 제어합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> epoch : 0, loss : 1.609931, accuracy : 0.312500, step : 776/21937 "
     ]
    }
   ],
   "source": [
    "import net.nets_factory as nets_factory\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import GeneratorEnqueuer\n",
    "from tensorflow.keras.utils import OrderedEnqueuer\n",
    "\n",
    "\n",
    "'''\n",
    "network list :\n",
    "    image size(224) : resnet50, resnet101, resnet152, resnet50_v2, resnet101_v2, resnet152_v2, vgg16, vgg19,\n",
    "                      densenet121, densenet169, densenet201, NASNet\n",
    "    image size(299) : inception_v3, inception_resnet_v2, xception\n",
    "\n",
    "'''\n",
    "network_name = 'resnet50_v2' #사용할 network 입력\n",
    "save_model_path = \"/home/june/model\" #model이 저장될 path\n",
    "network_fn = nets_factory.get_network(network_name)\n",
    "model = network_fn(include_top=True, weights=None, classes=len(class_num))\n",
    "\n",
    "'''\n",
    "scheduler를 이용한 learning rate 적용. overfitting을 방지하기 위해 step수에 따라 \n",
    "learning rate가 지수적으로 감소한다.\n",
    "'''\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                    decay_steps=5000,\n",
    "                                                    decay_rate=0.96,\n",
    "                                                    staircase=True)\n",
    "\n",
    "\n",
    "'''\n",
    "network의 weight를 최적화하는 과정에서 사용되는 알고리즘입니다.\n",
    "주로 사용되는 SGD(Stochastic Gradient Descent), RMSprop(Root Mean Square Propogation) \n",
    "Adam(ADAptive with Momentum)을 사용하여 back Propogation을 진행하였습니다.\n",
    "'''\n",
    "#optimizer = optimizers.SGD(learning_rate = lr_schedule)\n",
    "optimizer = optimizers.RMSprop(learning_rate = lr_schedule)\n",
    "#optimizer = optimizers.Adam(learning_rate = lr_schedule, beta_1 = 0.9,\n",
    "                            #beta_2 = 0.999, epsilon = 1e-08, decay= 0.)\n",
    "#optimizer = optimizers.Adagrad(learning_rate = lr_schedule)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "iterator를 사용하여 생성한 data batch를 대기열에 넣기위해 queue를 생성합니다.\n",
    "'''\n",
    "def create_data_queue(train_generator):\n",
    "    is_sequence = isinstance(train_generator, Sequence)\n",
    "    wait_time = 0.01\n",
    "    if is_sequence:\n",
    "        enqueuer = OrderedEnqueuer(train_generator,\n",
    "                                use_multiprocessing=False,\n",
    "                                shuffle = True)\n",
    "    else:\n",
    "        enqueuer = GeneratorEnqueuer(train_generator,\n",
    "                                use_multiprocessing =False,\n",
    "                                wait_time = wait_time)\n",
    "    return enqueuer\n",
    "\n",
    "\n",
    "\n",
    "enqueuer = create_data_queue(train_generator)\n",
    "enqueuer.start(workers = 1, max_queue_size=10)\n",
    "output_generator = enqueuer.get()\n",
    "accuracy_mean = 0.\n",
    "current_step = 0\n",
    "current_epoch = 1\n",
    "max_iter = len(filenames) / batch_size\n",
    "\n",
    "'''\n",
    "입력된 epoch만큼의 훈련을 진행합니다. \n",
    "기기의 성능을 고려하고 batch별 데이터를 실시간으로 확인하기위해 train_on_batch를 사용하였습니다.\n",
    "'''\n",
    "\n",
    "\n",
    "try:\n",
    "    while current_step < epoch * max_iter:\n",
    "        if current_step%max_iter == 0:\n",
    "            accuracy_mean = 0.\n",
    "            current_epoch = int(current_step/max_iter)\n",
    "            \n",
    "        # queue를 사용한 데이터 제어                \n",
    "        generator_output = next(output_generator)\n",
    "        x, y = generator_output\n",
    "        loss, accuracy = model.train_on_batch(x,y)            \n",
    "        accuracy_mean = ((accuracy_mean * current_step-(max_iter*current_epoch))+accuracy) / (current_step-(max_iter*current_epoch)+1)\n",
    "                \n",
    "        sys.stdout.write('\\r>> epoch : %d, loss : %f, accuracy : %f, step : %d/%d ' % (current_epoch, loss, accuracy, current_step, epoch * max_iter))\n",
    "        sys.stdout.flush()\n",
    "        current_step += 1\n",
    "        \n",
    "        # model save \n",
    "        if current_step%1000 ==0 :\n",
    "            model.save_weights(os.path.join(save_model_path,'%s_%s_%d.ckpt'%('Adam',network_name,current_step)))\n",
    "            \n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    enqueuer.stop(timeout=0.01)\n",
    "    \n",
    "enqueuer.stop(timeout=0.01) #queue 종료\n",
    "model.save_weights(os.path.join(save_model_path,'%s_%s_%d.ckpt'%('rms',network_name,epoch)))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inference\n",
    "* 훈련한 모델을 가지고 테스트를 진행하는 단계입니다.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_file_path = \"/data/test_vision.csv\"\n",
    "import net.nets_factory as nets_factory\n",
    "from tensorflow.keras.preprocessing import image as kimage\n",
    "import csv, os\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "import collections\n",
    "\n",
    "\n",
    "\n",
    "def load_image(image_file_path):\n",
    "        img = kimage.load_img(image_file_path, target_size=(image_size, image_size))\n",
    "        x = kimage.img_to_array(img)\n",
    "        x /= 255.\n",
    "        return x\n",
    "    \n",
    "result = []\n",
    "result2 = []\n",
    "data_file_path = \"/data/faces_images\"\n",
    "save_model_path = \"/home/june/model/res50_rms_8000\"\n",
    "network_fn = nets_factory.get_network('resnet50_v2')\n",
    "#network_fn2 = nets_factory.get_network('inception_resnet_v2')\n",
    "model = network_fn(include_top=True, weights=None, classes=6)\n",
    "#model2 = network_fn2(include_top=True, weights=None, classes=6)\n",
    "image_size = 224\n",
    "\n",
    "'''\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(0.001,\n",
    "                                                    decay_steps=15000,\n",
    "                                                    decay_rate=0.96,\n",
    "                                                    staircase=True)\n",
    "\n",
    "#optimizer = optimizers.SGD(learning_rate = lr_schedule)\n",
    "#optimizer = optimizers.Adagrad(learning_rate = lr_schedule)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate = lr_schedule, beta_1 = 0.9,\n",
    "                            beta_2 = 0.999, epsilon = 1e-08, decay= 0.)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#model2.compile(loss='categorical_crossentropy',\n",
    "                #optimizer=optimizer,\n",
    "                #metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "\n",
    "model.load_weights(os.path.join(save_model_path,\"Adam_resnet50_v2_8.ckpt\"))\n",
    "#model2.load_weights(os.path.join(save_model_path,\"Adam_inception_resnet_v2_20.ckpt\"))\n",
    "count = collections.Counter()\n",
    "stack = []\n",
    "with open(test_file_path) as path_list:\n",
    "    for image_path in enumerate(path_list):\n",
    "        if image_path[0] is 0 : continue\n",
    "        img = load_image(os.path.join(data_file_path,image_path[1].split(\"\\n\")[0]))\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        softmax = model.predict(x, batch_size=1)\n",
    "        #softmax2 = model.predict(x, batch_size=1)\n",
    "        result.append(np.asarray(softmax).argmax() + 1)\n",
    "        #result2.append(np.asarray(softmax).argmax() + 1)\n",
    "        #print(result)\n",
    "        #print(result2)\n",
    "        \n",
    "        #exit()\n",
    "#df = pd.DataFrame(result, columns=['label'])\n",
    "#df.to_csv(\"/data/result.csv\")\n",
    "f = open('/data/result_rms_resnet50V2_noised_8.csv','w')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['prediction'])\n",
    "for i in result:\n",
    "    wr.writerow([i])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
