{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/data/_newtrain_vision.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f009aacd687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mwr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_file_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpath_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/data/_newtrain_vision.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv, os\n",
    "import random\n",
    "\n",
    "data_file_path = \"/data/faces_images\"\n",
    "label_file_path = \"/data/_newtrain_vision.csv\"\n",
    "\n",
    "f = open('/data/new_train_vision.csv','w')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['filename','label'])\n",
    "with open(label_file_path) as path_list:\n",
    "    for data in enumerate(path_list):\n",
    "        if data[0] is 0: continue\n",
    "        filename, label = data[1].split(\",\")\n",
    "        filepath = os.path.join(data_file_path,filename)\n",
    "        #img = Image.open(filepath)\n",
    "        wr.writerow([filename, int(label)])\n",
    "        for i in range(1,4):\n",
    "            #img = img.rotate(90)\n",
    "            #img.save(os.path.join(data_file_path,'rot'+str(90*i)+'_'+filename))\n",
    "            wr.writerow(['rot'+str(90*i)+'_'+filename, int(label)])\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "Found 5850 images for training.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import preprocess.image as image\n",
    "import tensorflow.keras.utils as utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import GeneratorEnqueuer\n",
    "from tensorflow.keras.utils import OrderedEnqueuer\n",
    "print (tf.__version__)\n",
    "import random\n",
    "\n",
    "data_file_path = \"/data/faces_images\"\n",
    "label_file_path = \"/data/train_vision.csv\"\n",
    "initial_learning_rate = 0.001\n",
    "image_size = 299\n",
    "class_num = 6\n",
    "batch_size = 8\n",
    "epoch = 20\n",
    "\n",
    "\n",
    "filenames = []\n",
    "labels = []\n",
    "with open(label_file_path) as path_list:\n",
    "    for data in enumerate(path_list):\n",
    "        if data[0] is 0: continue\n",
    "        filename, label = data[1].split(\",\")\n",
    "        filenames.append(os.path.join(data_file_path,filename))\n",
    "        labels.append(int(label)-1)\n",
    "    #random.seed(1)    \n",
    "    #random.shuffle(filenames)\n",
    "    #random.shuffle(labels)\n",
    "    print('Found %d images for training.' % (len(filenames)))\n",
    "    \n",
    "class_num = list(range(class_num))\n",
    "train_datagen = image.ImageDataGenerator(rescale=1. / 255,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True)\n",
    "    \n",
    "train_generator = train_datagen.flow_from_mapfile(class_num,filenames,labels,\n",
    "                                            target_size=(image_size,image_size),\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> epoch : 1, loss : 0.139122, accuracy : 1.000000, step : 9445/731 "
     ]
    }
   ],
   "source": [
    "import net.nets_factory as nets_factory\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "network_name = 'inception_resnet_v2'\n",
    "save_model_path = \"/home/june/model\"\n",
    "network_fn = nets_factory.get_network(network_name)\n",
    "model = network_fn(include_top=True, weights=None, classes=len(class_num))\n",
    "\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                    decay_steps=1000,\n",
    "                                                    decay_rate=0.9,\n",
    "                                                    staircase=False)\n",
    "#optimizer = optimizers.SGD(learning_rate = lr_schedule)\n",
    "#optimizer = optimizers.RMSprop(learning_rate = lr_schedule)\n",
    "optimizer = optimizers.Adagrad(learning_rate = lr_schedule)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#model.load_weights(os.path.join(save_model_path,\"inception_v3_10.ckpt\"))\n",
    "\n",
    "def create_data_queue(train_generator):\n",
    "    is_sequence = isinstance(train_generator, Sequence)\n",
    "    wait_time = 0.01\n",
    "    if is_sequence:\n",
    "        enqueuer = OrderedEnqueuer(train_generator,\n",
    "                                use_multiprocessing=False,\n",
    "                                shuffle = False)\n",
    "    else:\n",
    "        enqueuer = GeneratorEnqueuer(train_generator,\n",
    "                                use_multiprocessing =False,\n",
    "                                wait_time = wait_time)\n",
    "    return enqueuer\n",
    "\n",
    "\n",
    "\n",
    "enqueuer = create_data_queue(train_generator)\n",
    "enqueuer.start(workers = 1, max_queue_size=10)\n",
    "output_generator = enqueuer.get()\n",
    "accuracy_mean = 0.\n",
    "current_step = 0\n",
    "current_epoch = 1\n",
    "max_iter = len(filenames) / batch_size\n",
    "\n",
    "try:\n",
    "    while current_step < epoch * max_iter:\n",
    "        generator_output = next(output_generator)\n",
    "        x, y = generator_output\n",
    "        loss, accuracy = model.train_on_batch(x,y)            \n",
    "        accuracy_mean = ((accuracy_mean * current_step)+accuracy) / (current_step+1)\n",
    "                \n",
    "        sys.stdout.write('\\r>> epoch : %d, loss : %f, accuracy : %f, step : %d/%d ' % (int(current_step/len(filenames)), loss, accuracy, current_step, max_iter))\n",
    "        sys.stdout.flush()\n",
    "        current_step += 1\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    enqueuer.stop(timeout=0.01)\n",
    "    exit()\n",
    "    \n",
    "enqueuer.stop(timeout=0.01)\n",
    "model.save_weights(os.path.join(save_model_path,'%s_%d_aug.ckpt'%(network_name,epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = \"/data/test_vision.csv\"\n",
    "import net.nets_factory as nets_factory\n",
    "from tensorflow.keras.preprocessing import image as kimage\n",
    "import csv, os\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def load_image(image_file_path):\n",
    "        img = kimage.load_img(image_file_path, target_size=(image_size, image_size))\n",
    "        x = kimage.img_to_array(img)\n",
    "        x /= 255.\n",
    "        return x\n",
    "    \n",
    "result = []\n",
    "data_file_path = \"/data/faces_images\"\n",
    "save_model_path = \"/home/june/model\"\n",
    "network_fn = nets_factory.get_network('inception_v3')\n",
    "model = network_fn(include_top=True, weights=None, classes=6)\n",
    "image_size = 299\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(0.001,\n",
    "                                                    decay_steps=1000,\n",
    "                                                    decay_rate=0.9,\n",
    "                                                    staircase=False)\n",
    "\n",
    "optimizer = optimizers.SGD(learning_rate = lr_schedule)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.load_weights(os.path.join(save_model_path,\"inception_v3_30.ckpt\"))\n",
    "\n",
    "             \n",
    "with open(test_file_path) as path_list:\n",
    "    for image_path in enumerate(path_list):\n",
    "        if image_path[0] is 0 : continue\n",
    "        img = load_image(os.path.join(data_file_path,image_path[1].split(\"\\n\")[0]))\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        softmax = model.predict(x, batch_size=1)\n",
    "        result.append(np.asarray(softmax).argmax() + 1)\n",
    "        \n",
    "#df = pd.DataFrame(result, columns=['label'])\n",
    "#df.to_csv(\"/data/result.csv\")\n",
    "f = open('/data/result_rms.csv','w')\n",
    "wr = csv.writer(f)\n",
    "wr.writerow(['prediction'])\n",
    "for i in result:\n",
    "    wr.writerow([i])\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
